{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "977b56c7-52e5-4c96-8d61-6c8a1d42585a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q tensorflow_addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6464839-2dea-48a0-ad4b-726863b49465",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "import keras \n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6995c329-e551-4586-9f86-a4d6e7c0392c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape (50000, 32, 32, 3) , y_train shape (50000, 1) \n",
      "x_test shape (10000, 32, 32, 3) , y_test shape (10000, 1) \n"
     ]
    }
   ],
   "source": [
    "(x_train , y_train) , (x_test , y_test) =  keras.datasets.cifar10.load_data()\n",
    "print(f'x_train shape {x_train.shape} , y_train shape {y_train.shape} ') # 50,000 samples \n",
    "print(f'x_test shape {x_test.shape} , y_test shape {y_test.shape} ') # 10,000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a04ceb2-d765-410b-a1c0-b7ddae8ff695",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyper-Parameters # \n",
    "# ===================== # \n",
    "num_classes = 10  \n",
    "input_shape = (32 , 32 ,3 ) # h ,w ,c\n",
    "learning_rate = 0.001 \n",
    "weight_decay = 0.0001\n",
    "batch_size = 256\n",
    "n_epochs = 40 \n",
    "n_patches = 144\n",
    "image_size = 72 # resize the input image \n",
    "patch_size = 6 # Size of the patches to be extracted from input images \n",
    "num_heads = 8 # attention heads \n",
    "projection_dim  = 64 # ideally 256 \n",
    "transformer_units = [ # represents transformer lyaer in terms of dimensions \n",
    "    projection_dim*2 ,\n",
    "    projection_dim\n",
    "] \n",
    "transformer_layers = 8 # 8 encoders and 8 decoders \n",
    "mlp_head_units = [2048 , 1024] #size of dense layers of the classifier \n",
    "\n",
    "\n",
    "# ====================== # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d995e74a-5e9d-4d40-b130-7cb32fc19939",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "                        [\n",
    "                            layers.Normalization(), # (x - mean(x)) / var(x)  \n",
    "                            layers.Resizing(image_size , image_size)  ,\n",
    "                            layers.RandomFlip('horizontal') , \n",
    "                            layers.RandomRotation(factor=0.02) ,\n",
    "                            layers.RandomZoom(height_factor=0.2,width_factor=0.2)\n",
    "                        ],\n",
    "                        name = 'data_augmenter'\n",
    "                    )\n",
    "data_augmentation.layers[0].adapt(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78b308c7-89ad-41b8-a87c-e89614771909",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mlp(x , hidden_units , dropout_rate) :\n",
    "    for unit in hidden_units : \n",
    "        x = layers.Dense(units = unit , activation = tf.nn.gelu)(x) \n",
    "        # GeLU - Gaussian Error Linear Unit || GeLU does well in nlp but is computationally costly \n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09fa9162-d23d-483a-a9d2-f55c612ff99a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CreatePatches(layers.Layer):\n",
    "    def __init__(self , patch_size ) :\n",
    "        super(CreatePatches , self ).__init__()\n",
    "        self.patch_size = patch_size \n",
    "        \n",
    "    def call(self , inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images = inputs , # input images \n",
    "            sizes = [1 , self.patch_size , self.patch_size ,1 ] ,\n",
    "            strides =  [1 , self.patch_size , self.patch_size ,1 ] ,\n",
    "            rates = [1,1,1,1] , # 1 means no dilation \n",
    "            padding = 'VALID' # if the shapes is short pad the patches \n",
    "        )\n",
    "        patch_dims = patches.shape[-1] \n",
    "        patches = tf.reshape(patches , [batch_size , -1 , patch_dims] ) \n",
    "        return patches \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4402b2a4-d4a4-46b1-82c0-1e552851a135",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Size 72 x 72\n",
      "Patch Size 6 x 6\n",
      "No. of Patches per Image 144\n",
      "Elements in 1 Patch 108\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUgAAAFICAYAAAAyFGczAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAWrElEQVR4nO3dS4+cd1bH8fNc69pVfXF32844jhMnDspARlwGCQmxZjUSL4eXAO8CiQViN2wGMSxYwCChRAwQDY5JMrFjt+1236rr/txYZImOzq+lKCD0/ayP/lVdT9Wvn8U5z0m6rusMAPA/pP/bbwAA/q8iIAHAQUACgIOABAAHAQkADgISABwEJAA4CEgAcBCQAODI1cK//PM/k+peb9uwZnr7B9JZvZ7y9rSMTxLxf4EwV5Sm2llffPJzqe7kyadhzd7xPems8WQvrHn6X4+ls9qulurSJK7pWm1gq2q018yEa/D01aV01u0PfxzW/MlPfiKdpXwWZmbb7Tas2Ww20llX1yup7ut/+VlY015fSmfleRbWlLn2YWTFUKqru/ia54n2PfvTv/ipVMcdJAA4CEgAcBCQAOAgIAHAQUACgIOABAAHAQkADgISABwEJAA45EmaTJwQyJK4sBM64s3MkiR+e53FHf3fniXWpfEkUJb3pLPKwViqU84rxGmD0c40rOlNd6Wz3rx8IdWN+2VY05n2BZInngST8UCqu3r9TVjz8vRUOuv+PW3iqRYmizph2kY9y8wsTYWfe6ZFQipMWWWZ9jvJMjUP4u9Z2mrTRyruIAHAQUACgIOABAAHAQkADgISABwEJAA4CEgAcBCQAOCQG8WTRmvAbJbx49+r6q50Vl7ENavltXTWYrGQ6rZV3JxbN5V01rOvn0l1s9k6rJnc1hrds7If1hwe35HOevLVc6nuerUMa25N4vdlZmadupohbui/cxA3zZuZFcOdsGZ+/ko764NHWl0/bvzPSq3Rei72Rrdp/IPqWm3lRScMVHTitey6RqprLa7rxJUdKu4gAcBBQAKAg4AEAAcBCQAOAhIAHAQkADgISABwEJAA4CAgAcAhT9KYxZ3zZmbV4iKsmZ2+lM5aLeIpmW+efimddXGmPTJ/tY6nQtZbbXRhcX0l1U0H8WqAO+KAwFYYShgOtVUQg/FIqnv2TTxlkqTiY/XFSY7pKJ7MOb51JJ21d/ROWHO9iCfEzMx+/nc/k+qaNv48RiNtzUaSa1NKTRevvUjF33kqrGaQJ2la7TVNmN4xcbWHijtIAHAQkADgICABwEFAAoCDgAQABwEJAA4CEgAcBCQAOG7QKK6ZXbwOa37xyb9LZ9XLWVhzcaU1Y29rsRk1iRtNK7EBVm1ZzdP4Mrw+O5fO2hnEqxmW8/hzNTNLOu0zS7L4NU+utOZ69TUPj47Dmt29uMbMbLQTr6BoVvEqDjOzv/npX0l1n30RDzhMduJVEGZm5UBr6P+dB/Hn8XAq7DkRdeK1bFpt5YIl8e9O+2XquIMEAAcBCQAOAhIAHAQkADgISABwEJAA4CAgAcBBQAKAg4AEAIc8SZMIXexmZkkVryx4/fVj6axMiW9h8sXMrKnF95/1wpo01V4zT7T/P/NFPNny+vREOmtcVGHNmzfaVM6by3jlhZlZX1gZUdfaKoV+oX1me9P9sGYw0VYuFP1JWHMw0L4/BxNt+uXyMp4AW8zn0lmVOIny4WG8wqHYjz9XM7NtFV9P8WdiiTiZ1girGbLveJaGO0gAcBCQAOAgIAHAQUACgIOABAAHAQkADgISABwEJAA4CEgAcNxgJ42WpTujuFt/PCils64W67hInKQxcSVN28W7R6bjsXiW9pqLVTz9sl0Jn4WZbav4D83LvnRWXmp7WIbCJE3XaGf1MvF6CtMXaaF9z3Z29+KzhO+Fmdl0FH8WZmaZMCYmrnSxxOKdQGZmrfKFbOLvonpWkmvxkog/zkSYklH3QKm4gwQABwEJAA4CEgAcBCQAOAhIAHAQkADgICABwEFAAoBDbhSvtlqjbCY0+vYS7RHx/TRuDN00Wjd2mRdSXao0t6qPkpd2RpgNh3Fzcb8fr4IwM+uENQ8b8VruT7SG+PEgfm+bRvv8C/GzTYUVIJvlQjprNIgbrbdX2lnDUmtOf/soXm3QiNdpsdGau3OLf3ddp63GsE64UOoQhzrF0Qnvn5ULAPD9ICABwEFAAoCDgAQABwEJAA4CEgAcBCQAOAhIAHAQkADguMHKBa3bvSziiYm81KZCbB1PCOSp9rj5TaVNCCgDAo1pKwv64iPnszJ+0b3pRDpr3I8nOdbDkXRWV2ufWVut4ppOu055T/vMFsvrsGZ28UI66+VX8X1CrxWnv8T3/+DuQVizI44VzTYbqW5H+Nl14p6HJBH+TmHy5dvDtPu0RKhT1zeouIMEAAcBCQAOAhIAHAQkADgISABwEJAA4CAgAcBBQAKAg4AEAIc8SdPUWod6Jky25MK0jZlZmsVnVeJOmm2jvf9RL35vfXHvSCns5zEza9v4vd062JPOun18K6wpRkvprHYzl+q6VVy3TeK9O2ZmSadNhbTCxMTLs5fSWcqU2Galva+z2YVUVxbxTy9NtEkm8WtmXSvsrlHXyAg7gRJxP4y6uqZTdtKo71/EHSQAOAhIAHAQkADgICABwEFAAoCDgAQABwEJAA4CEgAccqN4lmlZ2u/FTdR5qTUNd2ncnNs1WgOv+FR3K8u4UXwgNPmamXXdVqpL8/jNbdZa0/b1YhzWHB0eSWfdv/2+VPfV54/DmsuF9vj9tNUu1HwRr1w4my2ksxab07Dm4vJcOmtVade8EwYqkkr8zLSfgCVDoXE70YY4zOIm9s60NRud2FBuytoLYbjkJriDBAAHAQkADgISABwEJAA4CEgAcBCQAOAgIAHAQUACgIOABACHPEmTmtbVXxTxJE3Ri6c9zMxyofN/dfVGOss67X9BJnTiF4V2VlNrXf1FrxfW9DJt2mA1iyc+Pnr0UDprb28i1f3DWTzls1gKj/s3s9sT7TO7uJqFNWWhnXW+iidulMf9m5ntjPpS3Vy4nMNzceXCG+2zLcbxlEybat/tTnjJThyQScT7NHU1w3eJO0gAcBCQAOAgIAHAQUACgIOABAAHAQkADgISABwEJAA49JULYpQqjabrzVo6a7aM66pG60ZtTOsyzfK4mbYstMfSa22+Zp3QxL5crKSzfrAfN0dfnHwlnfUfv7yS6paLZVgz3dmRzqoqbU3CZh3vGUha7Zr38riu7rSzylz7SfV68XndVluzMZ5pTexZIzTOi93YSlUqrlJIU62ua9q4RrxOKu4gAcBBQAKAg4AEAAcBCQAOAhIAHAQkADgISABwEJAA4CAgAcAhT9Ik4iRKkcV1y8W1dNbr16dhzaCv/QmFOOFQKisjynhFgplZr4zPMjNbrLdhTb2Jp1XMzCph4ObTT/9VOqvsjaS6jx89CGtOL7UJmXajTVU8fOd2WPPsRfz9MTNr63hCo9/X1jeokxxVK0yFFHGNmVkprAkxM+uyeB1Eqq5cSOO/UzzKEnGdRZLEf2eSaJ+ZijtIAHAQkADgICABwEFAAoCDgAQABwEJAA4CEgAcBCQAOAhIAHDIkzRto21YKaTlNdq0RFVXYU3ftP0wu7u7Ut2gH0/J1Nt48sXMbDLWJlEOD/biorU2ffT583iPzPGuNgk0OZhIdS8v4imfRLzmd4+Fz8LMyiL+niWJ9v//xYuTuEiYHDEzy8TxkSyNp0LyiXadsjL+nZiZFW18DZJW+50rA0Pq55+YOP3SCe8/0b5nKu4gAcBBQAKAg4AEAAcBCQAOAhIAHAQkADgISABwEJAA4JAbxVP1UeZdXKe13JpVddy0mmVao7jYp2yrpbDaYDCQzuoNhlLdgwfvhjVtpTUDv1XNw5of3t+Vznr8PD7LzGwlfDWWl2fSWYnFawHMzF69moU1x1PtrLyZhjVPX8UN+GZmg6H2O+mX8fe2nGqDBqPeWqpLu/j31Lba90z5PXVCY7eZWZJoiZAozfria6q4gwQABwEJAA4CEgAcBCQAOAhIAHAQkADgICABwEFAAoCDgAQAhz5JI46i5Fn8KPmiiGvMzFqhK74Wpm3MzObLlVSXCl39gx3tUfh5qdWdX8XrFKb7R9JZf/SHP46LFi+ks+5Vr6W6bBivZpjND6SzeslGqkuq+Hqenp5KZw3G8ftXp1VacWVB28T3JnWinZXl2n1OIaxASDJxqqWOf5tt20hnta32/rXz1Dk9DXeQAOAgIAHAQUACgIOABAAHAQkADgISABwEJAA4CEgAcBCQAOCQJ2lyZR+EmbQTYlBoe2QSIb8Xy4V0lrhRxyaTeKqiUycEam0qJGviqZDVPJ62MTO72IzDmt3RA+ms6fGOVLfp4q/R20eldFZ3/Vyqa5fxvpznJ9okzenzV2FNKX5nl8KEiZlZJ0zcqFMthbiGpeziCbYu065Tmmzjs4TJHTN5XZRJv+Luu73n4w4SABwEJAA4CEgAcBCQAOAgIAHAQUACgIOABAAHAQkADrlRPDHt8e9NU8UvmmsrF4TtDZaIj1gfjYZSXSK0rdbbuEnWzGy71tY87PSnYU2vrzWnn53FzdGjdz+QzsoPtTUJeRtf82QdN2ObmV3PLqS6ehs34e9NtGueJ/Fn22R96azlPP4szMzKLP4OFan285yO4+EAM7M6j5vAF632e1LaydXlB6k4hCLMoJgJK1NugjtIAHAQkADgICABwEFAAoCDgAQABwEJAA4CEgAcBCQAOAhIAHDokzSJ9mD0tosfi16W2mPdyzJ+zH1Z9qSzUrHDvtqsw5p1oi1w2G61v3N2dRnW3NuJV0GYmfXS+DrNZ9r6hlSceCrK+Gs0nh5JZ1UXu1Jd3sVTSvsH2oTJy9NZWPPViTbh0zRLqW46iD/b5UqbXlvk2n1Ovx9/H3Pxu63oxFkadfYlESZuulZf4KDgDhIAHAQkADgISABwEJAA4CAgAcBBQAKAg4AEAAcBCQAOuVG8a7VH/nddXDcdj6SzhjuHYU3baGsNKuER/WZmdSI8ll5s4K1arbl7tY6b0xfLuXTWo8O9sObw/nvSWf2htrLg2dMvw5rzK605fbh7LNUVqfCZXWuf2eU2bkC+mMevZ2bWF39RhdDcvV5r6xuevLmS6o6m8W/zdqJd840weKE2infCmhMzM2UzQyuepeIOEgAcBCQAOAhIAHAQkADgICABwEFAAoCDgAQABwEJAA4CEgAc8iRNU2td/W0TP7L9YLojnTU5vB/WzM6eSWc1lTZtYF285qHttG79mTh90d2KP4/r2bl01vmrr8Oat979SDprd7or1S2F6Zeu1dY35Kat0Fis48mo06X23ZjNFmHNdKS9r36q/Z2Xi21YMxMntn4trNkwM2uFdQr3xJUF2yS+t0rVqRZ5+EUpZJIGAL4XBCQAOAhIAHAQkADgICABwEFAAoCDgAQABwEJAA4CEgAc+iRNo3X1r1bxhMCgjKdVzMxG06OwZrPV3tfmUptqadJ4J81krL3/2rSpiqtVvCtkFL8tMzN7+uTfwprJ/l3prKKn7SeZ3joQavals+pa2x00ObwX1uzdPpHOss0sLLl4rU3lLLbad2O1jad3tllfOmt9NJbqknF8P6TslPq2MF4Qk4hDLYm6u0aYYGvbeFroJriDBAAHAQkADgISABwEJAA4CEgAcBCQAOAgIAHAQUACgENuFK8rrSG7auJG316uNYZmWdxoPZjGj/s3M7NOWxnR5PGj9WebU+msxLSm51dCE/uhuP5gPY9XM3zyj38rnbXZak3Dh3ffDmv2DrXrNJpoDeU742lYkxzfkc6y+euw5LNfnElHrc7iBnAzs8EoXrNRrbRO68mtQ6kuLS7CmqbVVpM0ymoDcX1D12n3aZ3wmkoz+U1wBwkADgISABwEJAA4CEgAcBCQAOAgIAHAQUACgIOABAAHAQkADnmSZrleSXV1HU/cZImWy1kW1xW9kXRWcesdqa4SHiWfrrRVCsvVS6lu0MSPiV/EmyzMzGzcix/5v7rU3tc///1fS3V3778f1nz8B38snZWWA61O+A5l2sCWFYPdsGa8q62pGFbaxM35eTzxtDRt5UI52ZPqzJZhRSt8/1Xi8garxYmb7+6d6biDBAAHAQkADgISABwEJAA4CEgAcBCQAOAgIAHAQUACgIOABACHPEmz3oijHEnc797vldJRHz58L6z51bM30ln1Wpt+abbx7ppy95501vGdI6kuW52ENY04bdBYPEmzszORzhr1tNmFdh5P5nz92T9JZw162nXa/+BHYc1qpe2HOX/1JKx5eaZNyDy/0CbO1mm8k2awsyudVQl7lMzMkia+nlU81GVmZnUTfx/zTPzOCu/LzMyS+LxWmEq7Ce4gAcBBQAKAg4AEAAcBCQAOAhIAHAQkADgISABwEJAA4NBXLoiN4pPxMKxZV3EztpnZB28Lj7nvT6WzHj/5Uqqr6uuwZlVpja354R2p7tZe/Jktr55LZ10uNmHN3o621qCXao/8Hw3jRuVuozX0X778XKp7c/BWfNaF9povvokb3a+Fz9XMTOifNjOztIyvedJoDeDqmoRGWFpQt9o9Uyv0Y6vbGxqhAdzMpEbxhkZxAPh+EJAA4CAgAcBBQAKAg4AEAAcBCQAOAhIAHAQkADgISABwyJM0VVVLdW0T1zWV2DnfxNM7v/HeO9JR88VSqvviy7gu3WiTQJcL7TN78OhhWDPvtLMWq3h6ZJJol73NtEmatohXOLxYaBMOsxPtOs3LeDLq7IU2PTW7voqLEu1eQplWMTNLhEka22jrJ0wcHuksPq8Wz2qFURrtV2KWiRM3aRK/ZqOM+NwAd5AA4CAgAcBBQAKAg4AEAAcBCQAOAhIAHAQkADgISABwyI3iYi+nNUKjuNJkambWVOuwZnekrQ/47R++L9VtNquw5tfPXmhnic/fX3Xxo/XvPfwt6azLkydhTVI20lmrWvt6XF3EDf3pJF6RYGa2XAsN1GZ29lm8muHy+X9KZ+334vffJlrTdi3+UvJe3FyvLVwwq7ba9bQu/huaTvvOdl38G6612QZrxXDJs/i9qY3uKu4gAcBBQAKAg4AEAAcBCQAOAhIAHAQkADgISABwEJAA4CAgAcAhT9LUjdatv97EUwlVK3b+15uwRHwSvh3t70p1v/fxR8Jrai96eqmtD3gziyeG3n3rnnTWQRHPX9SrmXSWes0tLcOSpphKR5XDeMLEzGx1Hk8zzecX0lndSvw7BVUdfxZmZtkonmoZZIX2mupygyYeWanFUZSkjadaOnEqJ0m1UZpamExrhfd1E9xBAoCDgAQABwEJAA4CEgAcBCQAOAhIAHAQkADgICABwEFAAoDjBpM0Wod9LSyYyBKtc369mYc1i1W8Q8bMbDLsS3W3b+2GNb/7m4+ks375q19LddfL+G/Y1NqEQN7bDWv6/bjGzKwz7TU363gSqE21r1q/1CZRevuHYc2kuS+dlc5fxTW5tpOmutLuOS4s/j0N+9pnoa6kqRfx764V9yilSp18+6W9prIvR53eUXEHCQAOAhIAHAQkADgISABwEJAA4CAgAcBBQAKAg4AEAIfcKN51WqN4JTz9XdxYYPV6EdbMrq6ls9qt9lj6NIvf3M4gXmtgZvb+/dtS3eMvnoY1V+LfORbeWyb8jWZmS6EB3MzM2vi7Md0dSEd1jXadEqHx/KMf/b50Vnr5JKx5dRKveDAzO1lp779XCGsqxAbqTFxZYEJZKw6EtMI1FyPDGvH9S8cJ7+smuIMEAAcBCQAOAhIAHAQkADgISABwEJAA4CAgAcBBQAKAg4AEAEfSfdfPKAeA/ye4gwQABwEJAA4CEgAcBCQAOAhIAHAQkADgICABwEFAAoCDgAQAx38D22Sx7wCCPQ0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 144 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the patches \n",
    "plt.figure(figsize = (4,4)) \n",
    "image = x_train[np.random.choice(range(x_train.shape[0]))]\n",
    "plt.imshow(image.astype('uint8'))\n",
    "plt.axis('off') \n",
    "\n",
    "resized_image = tf.image.resize(\n",
    "            tf.convert_to_tensor([image]) , size=(image_size , image_size) \n",
    ")\n",
    "patches = CreatePatches(patch_size = patch_size )(resized_image) \n",
    "print(f'Image Size {image_size} x {image_size}')\n",
    "print(f'Patch Size {patch_size} x {patch_size}')\n",
    "print(f'No. of Patches per Image {patches.shape[1]}')\n",
    "print(f'Elements in 1 Patch {patches.shape[-1]}')\n",
    "\n",
    "n = int(np.sqrt(patches.shape[1]))\n",
    "plt.figure(figsize=(4,4)) \n",
    "for i , patch in enumerate(patches[0]) : \n",
    "    ax = plt.subplot(n , n ,  i+1)\n",
    "    patch_img = tf.reshape(patch , (patch_size , patch_size ,3 ))\n",
    "    plt.imshow(patch_img.numpy().astype('uint8'))\n",
    "    plt.axis('off') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "272c9c37-fcf8-4301-a270-2746c0400ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEncoder(layers.Layer) : \n",
    "    def __init__(self , n_patches , projection_dim ) : \n",
    "        super(PatchEncoder , self ).__init__()\n",
    "        self.n_patches = n_patches \n",
    "        self.projection_dim = projection_dim \n",
    "        self.projection = layers.Dense(units = self.projection_dim) \n",
    "        self.embedding = layers.Embedding(input_dim = self.n_patches , \n",
    "                                         output_dim = self.projection_dim)\n",
    "    \n",
    "    def call(self , patch ):\n",
    "        position = tf.range(0 , self.n_patches , delta = 1 ) \n",
    "        encoded  =  self.projection(patch) + self.embedding(position) \n",
    "        return encoded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a4c22b7-211a-4731-a74e-12a26fab9455",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_ViT_Classifier():\n",
    "    inputs = layers.Input(shape = input_shape )\n",
    "    augmented_data = data_augmentation(inputs) # augmentation \n",
    "    patches = CreatePatches(patch_size)(augmented_data)\n",
    "    encoded = PatchEncoder(n_patches  , projection_dim )(patches) \n",
    "    \n",
    "    # create multiples layers of transformer block \n",
    "    for _ in range(transformer_layers) : \n",
    "        # layer normalization \n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded)\n",
    "        attention_output = layers.MultiHeadAttention( # self attention \n",
    "                    num_heads = num_heads , \n",
    "                    key_dim = projection_dim , \n",
    "                    dropout = 0.1 \n",
    "        )(x1,x1)\n",
    "        # Skip Connection 1\n",
    "        x2 = layers.Add()([attention_output , encoded])\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6) (x2) \n",
    "        # MLP \n",
    "        x3 = mlp(x3 , transformer_units , 0.1  )\n",
    "        enocoded = layers.Add()([x3 , x2] )\n",
    "        \n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded)\n",
    "    representation = layers.Flatten()(representation) \n",
    "    representation = layers.Dropout(0.5)(representation) \n",
    "    features = mlp(representation , mlp_head_units , 0.5 ) \n",
    "    # Classify \n",
    "    logits = layers.Dense(num_classes )(features)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs , outputs= logits) \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f18af1c0-d5c2-43a8-8f91-d7a3e035a55b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " data_augmenter (Sequential)  (None, 72, 72, 3)        7         \n",
      "                                                                 \n",
      " create_patches_1 (CreatePat  (None, None, 108)        0         \n",
      " ches)                                                           \n",
      "                                                                 \n",
      " patch_encoder (PatchEncoder  (None, 144, 64)          16192     \n",
      " )                                                               \n",
      "                                                                 \n",
      " layer_normalization_16 (Lay  (None, 144, 64)          128       \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 2048)              18876416  \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 10)                10250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,001,169\n",
      "Trainable params: 21,001,162\n",
      "Non-trainable params: 7\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ViT = create_ViT_Classifier()\n",
    "ViT.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e48f4481-e14d-41d4-9c73-ea97f736a80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model):\n",
    "    optimizer = tfa.optimizers.AdamW(learning_rate=learning_rate , \n",
    "                                    weight_decay = weight_decay)\n",
    "    checkpoint_filepath = './temp/checkpoint'\n",
    "    checkpoint_callback = keras.callbacks.ModelCheckpoint(checkpoint_filepath ,\n",
    "                                                           monitor = 'val_accuracy' , \n",
    "                                                           save_best_only = True , \n",
    "                                                           save_weights_only=True )\n",
    "    model.compile(optimizer ,\n",
    "                  loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics = [keras.metrics.SparseCategoricalAccuracy(name=\"Accuracy\") ,\n",
    "                            keras.metrics.SparseTopKCategoricalAccuracy(5 , name=\"Top5Accuracy\")] )\n",
    "    history = model.fit(x = x_train , y = y_train ,\n",
    "                       batch_size = batch_size , \n",
    "                       epochs = n_epochs , \n",
    "                       validation_split=0.1 ,\n",
    "                       callbacks = [checkpoint_callback],)\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    _ , accuracy , top5accuracy = model.evaluate(x_test ,y_test)\n",
    "    print(f'Test Accuracy  : {round(accuracy * 100 , 2)} %' ) \n",
    "    print(f'Top 5 Test Accuracy  : {round(top5accuracy * 100 , 2)} %')\n",
    "    \n",
    "    return history , model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e126e6cb-4dbf-4916-8f8a-a0f9e43857d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "176/176 [==============================] - ETA: 0s - loss: 2.2221 - Accuracy: 0.2898 - Top5Accuracy: 0.7856WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "176/176 [==============================] - 108s 601ms/step - loss: 2.2221 - Accuracy: 0.2898 - Top5Accuracy: 0.7856 - val_loss: 1.6488 - val_Accuracy: 0.4132 - val_Top5Accuracy: 0.8842\n",
      "Epoch 2/40\n",
      "176/176 [==============================] - ETA: 0s - loss: 1.7676 - Accuracy: 0.3684 - Top5Accuracy: 0.8565WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "176/176 [==============================] - 106s 601ms/step - loss: 1.7676 - Accuracy: 0.3684 - Top5Accuracy: 0.8565 - val_loss: 1.5479 - val_Accuracy: 0.4562 - val_Top5Accuracy: 0.9052\n",
      "Epoch 3/40\n",
      "176/176 [==============================] - ETA: 0s - loss: 1.6727 - Accuracy: 0.4035 - Top5Accuracy: 0.8772WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "176/176 [==============================] - 106s 603ms/step - loss: 1.6727 - Accuracy: 0.4035 - Top5Accuracy: 0.8772 - val_loss: 1.4756 - val_Accuracy: 0.4732 - val_Top5Accuracy: 0.9174\n",
      "Epoch 4/40\n",
      "176/176 [==============================] - ETA: 0s - loss: 1.6164 - Accuracy: 0.4202 - Top5Accuracy: 0.8871WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "176/176 [==============================] - 105s 600ms/step - loss: 1.6164 - Accuracy: 0.4202 - Top5Accuracy: 0.8871 - val_loss: 1.4146 - val_Accuracy: 0.4954 - val_Top5Accuracy: 0.9244\n",
      "Epoch 5/40\n",
      "176/176 [==============================] - ETA: 0s - loss: 1.5748 - Accuracy: 0.4340 - Top5Accuracy: 0.8978WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "176/176 [==============================] - 102s 582ms/step - loss: 1.5748 - Accuracy: 0.4340 - Top5Accuracy: 0.8978 - val_loss: 1.3967 - val_Accuracy: 0.4940 - val_Top5Accuracy: 0.9252\n",
      "Epoch 6/40\n",
      "176/176 [==============================] - ETA: 0s - loss: 1.5473 - Accuracy: 0.4452 - Top5Accuracy: 0.9026WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "176/176 [==============================] - 105s 596ms/step - loss: 1.5473 - Accuracy: 0.4452 - Top5Accuracy: 0.9026 - val_loss: 1.3636 - val_Accuracy: 0.5134 - val_Top5Accuracy: 0.9312\n",
      "Epoch 7/40\n",
      "176/176 [==============================] - ETA: 0s - loss: 1.5109 - Accuracy: 0.4578 - Top5Accuracy: 0.9069WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "176/176 [==============================] - 104s 588ms/step - loss: 1.5109 - Accuracy: 0.4578 - Top5Accuracy: 0.9069 - val_loss: 1.3243 - val_Accuracy: 0.5304 - val_Top5Accuracy: 0.9376\n",
      "Epoch 8/40\n",
      "176/176 [==============================] - ETA: 0s - loss: 1.4848 - Accuracy: 0.4645 - Top5Accuracy: 0.9135WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "176/176 [==============================] - 105s 597ms/step - loss: 1.4848 - Accuracy: 0.4645 - Top5Accuracy: 0.9135 - val_loss: 1.3167 - val_Accuracy: 0.5322 - val_Top5Accuracy: 0.9406\n",
      "Epoch 9/40\n",
      "176/176 [==============================] - ETA: 0s - loss: 1.4668 - Accuracy: 0.4788 - Top5Accuracy: 0.9167WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "176/176 [==============================] - 106s 602ms/step - loss: 1.4668 - Accuracy: 0.4788 - Top5Accuracy: 0.9167 - val_loss: 1.2820 - val_Accuracy: 0.5370 - val_Top5Accuracy: 0.9462\n",
      "Epoch 10/40\n",
      "176/176 [==============================] - ETA: 0s - loss: 1.4404 - Accuracy: 0.4851 - Top5Accuracy: 0.9190WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "176/176 [==============================] - 107s 605ms/step - loss: 1.4404 - Accuracy: 0.4851 - Top5Accuracy: 0.9190 - val_loss: 1.2702 - val_Accuracy: 0.5540 - val_Top5Accuracy: 0.9484\n",
      "Epoch 11/40\n",
      "176/176 [==============================] - ETA: 0s - loss: 1.4152 - Accuracy: 0.4951 - Top5Accuracy: 0.9220WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "176/176 [==============================] - 105s 599ms/step - loss: 1.4152 - Accuracy: 0.4951 - Top5Accuracy: 0.9220 - val_loss: 1.2653 - val_Accuracy: 0.5506 - val_Top5Accuracy: 0.9508\n",
      "Epoch 12/40\n",
      "176/176 [==============================] - ETA: 0s - loss: 1.3989 - Accuracy: 0.5019 - Top5Accuracy: 0.9251WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "176/176 [==============================] - 105s 597ms/step - loss: 1.3989 - Accuracy: 0.5019 - Top5Accuracy: 0.9251 - val_loss: 1.2272 - val_Accuracy: 0.5688 - val_Top5Accuracy: 0.9528\n",
      "Epoch 13/40\n",
      "176/176 [==============================] - ETA: 0s - loss: 1.3772 - Accuracy: 0.5096 - Top5Accuracy: 0.9279WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "176/176 [==============================] - 104s 592ms/step - loss: 1.3772 - Accuracy: 0.5096 - Top5Accuracy: 0.9279 - val_loss: 1.2312 - val_Accuracy: 0.5592 - val_Top5Accuracy: 0.9484\n",
      "Epoch 14/40\n",
      "176/176 [==============================] - ETA: 0s - loss: 1.3544 - Accuracy: 0.5145 - Top5Accuracy: 0.9324WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "176/176 [==============================] - 103s 586ms/step - loss: 1.3544 - Accuracy: 0.5145 - Top5Accuracy: 0.9324 - val_loss: 1.2016 - val_Accuracy: 0.5760 - val_Top5Accuracy: 0.9518\n",
      "Epoch 15/40\n",
      "176/176 [==============================] - ETA: 0s - loss: 1.3395 - Accuracy: 0.5253 - Top5Accuracy: 0.9339WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "176/176 [==============================] - 103s 584ms/step - loss: 1.3395 - Accuracy: 0.5253 - Top5Accuracy: 0.9339 - val_loss: 1.1909 - val_Accuracy: 0.5776 - val_Top5Accuracy: 0.9522\n",
      "Epoch 16/40\n",
      "176/176 [==============================] - ETA: 0s - loss: 1.3181 - Accuracy: 0.5311 - Top5Accuracy: 0.9358WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "176/176 [==============================] - 105s 594ms/step - loss: 1.3181 - Accuracy: 0.5311 - Top5Accuracy: 0.9358 - val_loss: 1.1622 - val_Accuracy: 0.5932 - val_Top5Accuracy: 0.9548\n",
      "Epoch 17/40\n",
      "176/176 [==============================] - ETA: 0s - loss: 1.2973 - Accuracy: 0.5389 - Top5Accuracy: 0.9381WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "176/176 [==============================] - 103s 588ms/step - loss: 1.2973 - Accuracy: 0.5389 - Top5Accuracy: 0.9381 - val_loss: 1.1803 - val_Accuracy: 0.5808 - val_Top5Accuracy: 0.9558\n",
      "Epoch 18/40\n",
      "176/176 [==============================] - ETA: 0s - loss: 1.2822 - Accuracy: 0.5458 - Top5Accuracy: 0.9391WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "176/176 [==============================] - 103s 586ms/step - loss: 1.2822 - Accuracy: 0.5458 - Top5Accuracy: 0.9391 - val_loss: 1.1440 - val_Accuracy: 0.5940 - val_Top5Accuracy: 0.9570\n",
      "Epoch 19/40\n",
      "176/176 [==============================] - ETA: 0s - loss: 1.2577 - Accuracy: 0.5518 - Top5Accuracy: 0.9425WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "176/176 [==============================] - 103s 586ms/step - loss: 1.2577 - Accuracy: 0.5518 - Top5Accuracy: 0.9425 - val_loss: 1.1287 - val_Accuracy: 0.6016 - val_Top5Accuracy: 0.9576\n",
      "Epoch 20/40\n",
      "176/176 [==============================] - ETA: 0s - loss: 1.2461 - Accuracy: 0.5574 - Top5Accuracy: 0.9451WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "176/176 [==============================] - 103s 587ms/step - loss: 1.2461 - Accuracy: 0.5574 - Top5Accuracy: 0.9451 - val_loss: 1.1104 - val_Accuracy: 0.6106 - val_Top5Accuracy: 0.9592\n",
      "Epoch 21/40\n",
      "176/176 [==============================] - ETA: 0s - loss: 1.2163 - Accuracy: 0.5684 - Top5Accuracy: 0.9475WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "176/176 [==============================] - 104s 589ms/step - loss: 1.2163 - Accuracy: 0.5684 - Top5Accuracy: 0.9475 - val_loss: 1.0957 - val_Accuracy: 0.6070 - val_Top5Accuracy: 0.9578\n",
      "Epoch 22/40\n",
      "176/176 [==============================] - ETA: 0s - loss: 1.1956 - Accuracy: 0.5763 - Top5Accuracy: 0.9482WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "176/176 [==============================] - 102s 581ms/step - loss: 1.1956 - Accuracy: 0.5763 - Top5Accuracy: 0.9482 - val_loss: 1.0887 - val_Accuracy: 0.6144 - val_Top5Accuracy: 0.9580\n",
      "Epoch 23/40\n",
      "176/176 [==============================] - ETA: 0s - loss: 1.1837 - Accuracy: 0.5768 - Top5Accuracy: 0.9511WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "176/176 [==============================] - 105s 595ms/step - loss: 1.1837 - Accuracy: 0.5768 - Top5Accuracy: 0.9511 - val_loss: 1.0702 - val_Accuracy: 0.6308 - val_Top5Accuracy: 0.9602\n",
      "Epoch 24/40\n",
      "176/176 [==============================] - ETA: 0s - loss: 1.1672 - Accuracy: 0.5851 - Top5Accuracy: 0.9524WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "176/176 [==============================] - 103s 588ms/step - loss: 1.1672 - Accuracy: 0.5851 - Top5Accuracy: 0.9524 - val_loss: 1.0627 - val_Accuracy: 0.6224 - val_Top5Accuracy: 0.9614\n",
      "Epoch 25/40\n",
      "176/176 [==============================] - ETA: 0s - loss: 1.1516 - Accuracy: 0.5902 - Top5Accuracy: 0.9538WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "176/176 [==============================] - 102s 580ms/step - loss: 1.1516 - Accuracy: 0.5902 - Top5Accuracy: 0.9538 - val_loss: 1.0428 - val_Accuracy: 0.6336 - val_Top5Accuracy: 0.9602\n",
      "Epoch 26/40\n",
      "176/176 [==============================] - ETA: 0s - loss: 1.1267 - Accuracy: 0.5998 - Top5Accuracy: 0.9564WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "176/176 [==============================] - 104s 592ms/step - loss: 1.1267 - Accuracy: 0.5998 - Top5Accuracy: 0.9564 - val_loss: 1.0284 - val_Accuracy: 0.6430 - val_Top5Accuracy: 0.9604\n",
      "Epoch 27/40\n",
      "176/176 [==============================] - ETA: 0s - loss: 1.1119 - Accuracy: 0.6026 - Top5Accuracy: 0.9576WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "176/176 [==============================] - 103s 585ms/step - loss: 1.1119 - Accuracy: 0.6026 - Top5Accuracy: 0.9576 - val_loss: 1.0294 - val_Accuracy: 0.6360 - val_Top5Accuracy: 0.9624\n",
      "Epoch 28/40\n",
      "176/176 [==============================] - ETA: 0s - loss: 1.0999 - Accuracy: 0.6111 - Top5Accuracy: 0.9589WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "176/176 [==============================] - 105s 594ms/step - loss: 1.0999 - Accuracy: 0.6111 - Top5Accuracy: 0.9589 - val_loss: 1.0097 - val_Accuracy: 0.6400 - val_Top5Accuracy: 0.9650\n",
      "Epoch 29/40\n",
      "176/176 [==============================] - ETA: 0s - loss: 1.0890 - Accuracy: 0.6146 - Top5Accuracy: 0.9599WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "176/176 [==============================] - 104s 590ms/step - loss: 1.0890 - Accuracy: 0.6146 - Top5Accuracy: 0.9599 - val_loss: 1.0169 - val_Accuracy: 0.6432 - val_Top5Accuracy: 0.9648\n",
      "Epoch 30/40\n",
      "176/176 [==============================] - ETA: 0s - loss: 1.0782 - Accuracy: 0.6158 - Top5Accuracy: 0.9624WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "176/176 [==============================] - 102s 577ms/step - loss: 1.0782 - Accuracy: 0.6158 - Top5Accuracy: 0.9624 - val_loss: 1.0157 - val_Accuracy: 0.6440 - val_Top5Accuracy: 0.9652\n",
      "Epoch 31/40\n",
      "176/176 [==============================] - ETA: 0s - loss: 1.0663 - Accuracy: 0.6229 - Top5Accuracy: 0.9624WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "176/176 [==============================] - 104s 591ms/step - loss: 1.0663 - Accuracy: 0.6229 - Top5Accuracy: 0.9624 - val_loss: 0.9898 - val_Accuracy: 0.6470 - val_Top5Accuracy: 0.9668\n",
      "Epoch 32/40\n",
      "176/176 [==============================] - ETA: 0s - loss: 1.0602 - Accuracy: 0.6263 - Top5Accuracy: 0.9621WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "176/176 [==============================] - 102s 578ms/step - loss: 1.0602 - Accuracy: 0.6263 - Top5Accuracy: 0.9621 - val_loss: 0.9920 - val_Accuracy: 0.6436 - val_Top5Accuracy: 0.9642\n",
      "Epoch 33/40\n",
      "176/176 [==============================] - ETA: 0s - loss: 1.0470 - Accuracy: 0.6270 - Top5Accuracy: 0.9645WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "176/176 [==============================] - 102s 581ms/step - loss: 1.0470 - Accuracy: 0.6270 - Top5Accuracy: 0.9645 - val_loss: 0.9944 - val_Accuracy: 0.6472 - val_Top5Accuracy: 0.9646\n",
      "Epoch 34/40\n",
      "176/176 [==============================] - ETA: 0s - loss: 1.0396 - Accuracy: 0.6334 - Top5Accuracy: 0.9650WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "176/176 [==============================] - 103s 583ms/step - loss: 1.0396 - Accuracy: 0.6334 - Top5Accuracy: 0.9650 - val_loss: 0.9741 - val_Accuracy: 0.6592 - val_Top5Accuracy: 0.9632\n",
      "Epoch 35/40\n",
      "176/176 [==============================] - ETA: 0s - loss: 1.0205 - Accuracy: 0.6349 - Top5Accuracy: 0.9666WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "176/176 [==============================] - 104s 592ms/step - loss: 1.0205 - Accuracy: 0.6349 - Top5Accuracy: 0.9666 - val_loss: 0.9865 - val_Accuracy: 0.6566 - val_Top5Accuracy: 0.9640\n",
      "Epoch 36/40\n",
      "176/176 [==============================] - ETA: 0s - loss: 1.0158 - Accuracy: 0.6383 - Top5Accuracy: 0.9669WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "176/176 [==============================] - 104s 590ms/step - loss: 1.0158 - Accuracy: 0.6383 - Top5Accuracy: 0.9669 - val_loss: 0.9719 - val_Accuracy: 0.6598 - val_Top5Accuracy: 0.9686\n",
      "Epoch 37/40\n",
      "176/176 [==============================] - ETA: 0s - loss: 1.0098 - Accuracy: 0.6413 - Top5Accuracy: 0.9666WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "176/176 [==============================] - 103s 584ms/step - loss: 1.0098 - Accuracy: 0.6413 - Top5Accuracy: 0.9666 - val_loss: 0.9605 - val_Accuracy: 0.6608 - val_Top5Accuracy: 0.9690\n",
      "Epoch 38/40\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.9961 - Accuracy: 0.6455 - Top5Accuracy: 0.9689WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "176/176 [==============================] - 103s 583ms/step - loss: 0.9961 - Accuracy: 0.6455 - Top5Accuracy: 0.9689 - val_loss: 0.9524 - val_Accuracy: 0.6692 - val_Top5Accuracy: 0.9662\n",
      "Epoch 39/40\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.9921 - Accuracy: 0.6467 - Top5Accuracy: 0.9689WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "176/176 [==============================] - 104s 590ms/step - loss: 0.9921 - Accuracy: 0.6467 - Top5Accuracy: 0.9689 - val_loss: 0.9621 - val_Accuracy: 0.6668 - val_Top5Accuracy: 0.9656\n",
      "Epoch 40/40\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.9853 - Accuracy: 0.6537 - Top5Accuracy: 0.9683WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "176/176 [==============================] - 101s 576ms/step - loss: 0.9853 - Accuracy: 0.6537 - Top5Accuracy: 0.9683 - val_loss: 0.9790 - val_Accuracy: 0.6602 - val_Top5Accuracy: 0.9658\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ./temp/checkpoint",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history , ViT \u001b[38;5;241m=\u001b[39m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mViT\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[21], line 18\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer ,\n\u001b[1;32m     10\u001b[0m               loss \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     11\u001b[0m               metrics \u001b[38;5;241m=\u001b[39m [keras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mSparseCategoricalAccuracy(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m) ,\n\u001b[1;32m     12\u001b[0m                         keras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mSparseTopKCategoricalAccuracy(\u001b[38;5;241m5\u001b[39m , name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop5Accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m)] )\n\u001b[1;32m     13\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(x \u001b[38;5;241m=\u001b[39m x_train , y \u001b[38;5;241m=\u001b[39m y_train ,\n\u001b[1;32m     14\u001b[0m                    batch_size \u001b[38;5;241m=\u001b[39m batch_size , \n\u001b[1;32m     15\u001b[0m                    epochs \u001b[38;5;241m=\u001b[39m n_epochs , \n\u001b[1;32m     16\u001b[0m                    validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m ,\n\u001b[1;32m     17\u001b[0m                    callbacks \u001b[38;5;241m=\u001b[39m [checkpoint_callback],)\n\u001b[0;32m---> 18\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_filepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m _ , accuracy , top5accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(x_test ,y_test)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Accuracy  : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(accuracy\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;250m \u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m %\u001b[39m\u001b[38;5;124m'\u001b[39m ) \n",
      "File \u001b[0;32m/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/tensorflow/python/training/py_checkpoint_reader.py:31\u001b[0m, in \u001b[0;36merror_translator\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m     27\u001b[0m error_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot found in checkpoint\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_message \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFailed to find any \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatching files for\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m error_message:\n\u001b[0;32m---> 31\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors_impl\u001b[38;5;241m.\u001b[39mNotFoundError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, error_message)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSliced checkpoints are not supported\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_message \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData type \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupported\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m error_message:\n\u001b[1;32m     36\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors_impl\u001b[38;5;241m.\u001b[39mUnimplementedError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, error_message)\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ./temp/checkpoint"
     ]
    }
   ],
   "source": [
    "history , ViT = run_experiment(ViT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faa2fcd-e7ba-4f23-ae12-6f4e25d2d573",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_metrics(history):\n",
    "    # Plotting accuracy and top-5 accuracy\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plotting Accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plotting Top-5 Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['top_k_categorical_accuracy'], label='Train Top-5 Accuracy')\n",
    "    plt.plot(history.history['val_top_k_categorical_accuracy'], label='Validation Top-5 Accuracy')\n",
    "    plt.title('Training and Validation Top-5 Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Top-5 Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plotting loss\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plotting Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Assuming `history` is the history object from model training\n",
    "# Replace `history` with your actual history object\n",
    "plot_metrics(history)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sagemaker-distribution:Python",
   "language": "python",
   "name": "conda-env-sagemaker-distribution-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
